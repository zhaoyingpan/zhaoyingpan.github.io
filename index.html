''
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Zhaoying Pan</title>
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Zhaoying</span> Pan</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>I am a second-year master's student in Electrical and Computer Engineering at the University of Michigan, specializing in computer vision.
                    I am honored to work with <a href="https://andrewowens.com/" target="_blank">Prof. Andrew Owens</a> since the summer of 2022. Earlier, I also colleborate with
                    Jinge Ma and Yutong Xie on an explorative project, advised by <a href="http://www-personal.umich.edu/~qmei/">Prof. Qiaozhu Mei</a></span>.
                    Before my master's program, I received my Bachelor of Engineering in Electronic and Information Engineering, from University of Chinese Academy of Sciences.
                    During my bachelor's study, I spent some wonderful time in the lab of <a href="https://people.ucas.ac.cn/~fukun">Prof. Kun Fu</a> and <a href="https://people.ucas.ac.cn/~sunxian" target="_blank">Prof. Xian Sun</a>,
                    and worked with Zhiqiang Yuan. <span style="color: red;">I am currently applying for Ph.D. positions of 2023 Fall!</span>
                </p>
                <p>
                    Email: panzy@umich.edu
                </p>
                <p>
                    <a href="assets/pdf/CV_zhaoyingpan.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:panzy@umich.edu" style="margin-right: 15px"><i class="far fa-envelope-open fa-lg"></i> Email</a>
                    <a href="https://scholar.google.com/citations?user=HmQECwsAAAAJ&hl=en&oi=ao" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Google Scholar</a>
                    <a href="https://github.com/zhaoyingpan" target="_blank" style="margin-right: 15px"><i class="fab fa-github fa-lg"></i> Github</a>
                    <a href="https://www.linkedin.com/in/zhaoying-pan-296942153/" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                </p>
    
            </div>
            <div class="col-md-4" style="">
                <img src="assets/img/profile.jpg" class="img-thumbnail" width="280px" alt="Profile picture">
                <!-- <img id="profile" src="assets/img/goose.jpg"  class="img-thumbnail" width="280px" alt="Profile picture" />
                <button onclick="document.getElementById('profile').src='assets/img/profile.jpg'">My photo</button>
                <button onclick="document.getElementById('profile').src='assets/img/goose.jpg'">Goose photo</button> -->
            </div>
        </div>


        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-10" style="">
                <h4>Education</h4>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/umich.png" alt="UM" width="100" height="100"></div><div class="col-sm-10">
                    <b>University of Michigan</b><span style="float: right;">2021-2023</span>
                    <br><span style="font-style: italic;">Master of Science</span> in Electrical and Computer Engineering
                    <br>Specialization: Computer Vision
                    <br>GPA: 4.0/4.0
                    <br>Advisor: <a href="https://andrewowens.com/" target="_blank">Prof. Andrew Owens </a>
                    <br>Selected Courses:
                        <ul>
                            <li>EECS 442 <a href="https://www.eecs.umich.edu/courses/eecs442-ahowens/fa21/">Computer Vision</a> (Prof. Andrew Owens) A+</li>
                            <li>EECS 598-008 <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/">Deep Learning for Computer Vision</a> (Prof. Justin Johnson) A+</li>
                            <li>EECS 549 Information Retrieval (Prof. David Jurgens) A+</li>
                            <li>EECS 542 <a href="https://web.eecs.umich.edu/~ahowens/eecs542/w22/">Advanced Computer Vision</a> (Prof. Andrew Owens) A</li>
                        </ul>
                </div> </div> </div>
                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/ucas.jpg" alt="UCAS" width="100" height="100"></div><div class="col-sm-10">
                    <b>University of Chinese Academy of Sciences</b> <span style="float: right;">2017-2021</span>
                    <br><span style="font-style: italic;">Bachelor of Engineering</span> in Electronic and Information Engineering
                    <br>GPA: 3.59/4.0
                    <br>Thesis: <span style="font-style: italic;">Image Caption Generating of High-Resolution Remote Sensing Images.</span> (Bachelor’s Thesis with Honors)
                    <br>Advisor: <a href="https://people.ucas.ac.cn/~fukun">Prof. Kun Fu</a> and <a href="https://people.ucas.ac.cn/~sunxian" target="_blank">Prof. Xian Sun</a> 
                </div> </div> </div>
                
                
            </div>
        </div>

        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/animation.png" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9"><a href="https://arxiv.org/abs/2212.00256">Face Animation with Multiple Source Images.</a>
                    <br> <span style="font-weight: bold";>Zhaoying Pan</span>*, <a href="https://github.com/jingema99/jingema.github.io" target="_blank">Jinge Ma</a>* (equal contribution)
                    <br><span style="font-style: italic;">arXiv</span>, 2022 
                    <br><a href="assets/pdf/2212.00256.pdf" target="_blank">Paper</a> / Code /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsepan2022face" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsepan2022face"><div class="card card-body"><pre><code>@article{pan2022face,
        title={Face Animation with Multiple Source Images},
        author={Pan, Zhaoying and Ma, Jinge},
        journal={arXiv preprint arXiv:2212.00256},
        year={2022}
}</pre></code></div></div>
                    <br> We proposed a flexible schema to enhance the performance of existing face-animation methods by enabling multiple source images as inputs.
</div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/selo.png" class="img-fluid img-thumbnail" alt="Project image"></div>
    <div class="col-sm-9"><a href="https://arxiv.org/abs/2209.06515">Learning to Evaluate Performance of Multi-modal Semantic Localization.</a>
    <br>Zhiqiang Yuan, Wenkai Zhang, Chongyang Li, <span style="font-weight: bold";>Zhaoying Pan</span>, Jialiang Chen, Yongqiang Mao, Shuoke Li, Hongqi Li, Xian Sun.
    <br><span style="font-style: italic;">IEEE Transactions on Geoscience and Remote Sensing</span>, 2022
    <br><a href="assets/pdf/2209.06515.pdf" target="_blank">Paper</a> / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseyuan2022learning" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseyuan2022learning"><div class="card card-body"><pre><code>@article{yuan2022learning,
    title={Learning to Evaluate Performance of Multi-modal Semantic Localization},
    author={Yuan, Zhiqiang and Zhang, Wenkai and Li, Chongyang and Pan, Zhaoying and Mao, Yongqiang and Chen, Jialiang and Li, Shouke and Wang, Hongqi and Sun, Xian},
    journal={arXiv preprint arXiv:2209.06515},
    year={2022}
}</pre></code></div></div>
    <br> We contributed test sets, evaluation metrics and baselines for evaluation of Semantic Localization (SeLo) tasks, and provided a detailed demo to use this evaluation framework.
</div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/sr.png" class="img-fluid img-thumbnail" alt="Project image"></div>
    <div class="col-sm-9"><a href="https://www.mdpi.com/2072-4292/14/19/4834">Diffusion Model with Detail Complement for Super-resolution of Remote Sensing.</a>
    <br>Jinzhe Liu, Zhiqiang Yuan, <span style="font-weight: bold";>Zhaoying Pan</span>, Yiqun Fu, Li Liu, Bin Lu.
    <br><span style="font-style: italic;">Remote Sensing</span>, 2022
    <br><a href="assets/pdf/remotesensing-14-04834.pdf" target="_blank">Paper</a> / Code /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseliu2022diffusion" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseliu2022diffusion"><div class="card card-body"><pre><code>@article{liu2022diffusion,
    title={Diffusion Model with Detail Complement for Super-Resolution of Remote Sensing},
    author={Liu, Jinzhe and Yuan, Zhiqiang and Pan, Zhaoying and Fu, Yiqun and Liu, Li and Lu, Bin},
    journal={Remote Sensing},
    volume={14},
    number={19},
    pages={4834},
    year={2022},
    publisher={MDPI}
}</pre></code></div></div>
    <br> We proposed the Diffusion Model with Detail Complement (DMDC) for the super-resolution task on remote sensing images.
</div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Current Research</h4>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/mm.gif" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Self-supervised Motion Magnification
                    <br><span style="font-style: italic;">Advisor: Prof. Andrew Owens</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#mm" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="mm"><div class="card card-body">
<ul>
    <li>I implemented an unsupervised approach for motion magnification with a sinusoidal representation network and a single video example as a toy example to demonstrate the effectiveness of using optical flow to guide the generation of magnified frames.</li>
    <li>I am currently working on training a network with the unsupervised approach on unlabeled video data for motion magnification.</li>
    <li><b>The left image shows the results with magnification factor of 2/4/8.</b></li>
</ul>

                        </pre></code></div></div>
                </div> </div> </div>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/prompt.png" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Artwork Space Exploration (Queries Analysis for Diffusion Models)
                    <br><span style="font-style: italic;">Colleborator: Jinge Ma and Yutong Xie. Advisor: <a href="http://www-personal.umich.edu/~qmei/">Prof. Qiaozhu Mei</a></span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#prompt" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="prompt"><div class="card card-body">First Stage (Artwork Space Exploration)
<ul>
    <li>We applied auto-encoder, CLIP, and artCLIP to construct the artwork representation space with several artwork datasets (WikiArt, Painter by numbers, Art500k).</li>
    <li>We explored and examined the characteristics of the representation space with dimensionality-reduction methods including PCA and UMAP.</li>
    <li>We also created the visualization of the dimensionality-reducted representations of artworks with style labels.</li>
    <li><b>The left image shows the visualization of 2D UMAP projection and 3D UMAP projection.</b></li>
</ul>
Second Stage (Queries Analysis for Diffusion Models))
<ul>
    <li>Given that it is hard to distengle the semantics and style in the image space, and inspired by the powerful diffusion models for text-to-image tasks, we are motivated to study the artwork space through the diffusion models and space of queries (input prompts for diffusion models).</li>
    <li>Currently we are working on the analysis of queries from different aspectives with several datasets, to better understand the representation space of artworks of the diffusion models.</li>
</ul>
                        </div></div>
                </div> </div> </div>
                
            </div>
        </div>

        
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Projects</h4>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/thesis.png" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Bachelor's Thesis: Image Caption Generating of High-Resolution Remote Sensing Images <span style="float: right;">Nov. 2020 - Apr. 2021</span>
                    <br><span style="font-style: italic;">Advisor: Prof. Kun Fu and Prof. Xian Sun</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#thesis" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="thesis"><div class="card card-body">
<ul>
    <li>I implemented image captioning algorithms, including <span style="font-style: italic;">Show and Tell</span>, <span style="font-style: italic;">Show, Attend and Tell</span>, Transformer, Attention on Attention (AoA), on three remote-sensing image datasets, Sydney-Captions Dataset, UCM-Captions Dataset, and RSICD Dataset.</li>
    <li>I compared and analyzed the trained models qualitatively and quantitatively to determine the best model for practical application.</li>
    <li>The conclusion is that the <span style="font-style: italic;">Show, Attend and Tell</span> and Transformer trained on RSICD dataset are recommended for applications.</li>
    <li>The left image shows an example of captions for remote sensing images, from RSICD dataset.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/prompt.png" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Object Detection Implementation<span style="float: right;">Aug. 2020 - Oct. 2020</span>
                    <br><span style="font-style: italic;">Advisor: Prof. Kun Fu and Prof. Xian Sun</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#yolo3" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="yolo3"><div class="card card-body">
<ul>
    <li>I reviewed object detection algorithms, including Faster-RCNN, YOLO v3, and YOLO v4.</li>
    <li>I implemented YOLO v3 with PyTorch on the DOTA dataset to detect objects in remote sensing images.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Image Captioning Implementation<span style="float: right;">Jul. 2019 - Aug. 2019</span>
                    <br><span style="font-style: italic;">Advisor: Prof. Kun Fu and Prof. Xian Sun</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#caption" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="caption"><div class="card card-body">
<ul>
    <li>I implemented simple CNN and LSTM with PyTorch and TensorFlow.</li>
    <li>I Implemented show and tell algorithm on UCM dataset with TensorFlow.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Internship at Institute of Computing Technology<span style="float: right;">Aug. 2020 - Oct. 2020</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#intern" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="intern"><div class="card card-body">
<ul>
    <li>I studied High-speed interface (JESD204B) and network LTE protocols.</li>
    <li>I researched and developed video compression algorithm based on JPEG XS.</li>
    <li>I investigated physical layer signal synchronization, frequency offset estimation, and compensation.</li>
    <li>I developed the low-latency I2S controller on FPGA.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">Development of portable electrocardiograph based on FPGA<span style="float: right;">Mar. 2020 - Jun. 2020</span>
                    <br><span style="font-style: italic;">Group Members: Jinge Ma, Jiu Chen, Zhihong Zeng, and Qianli Ma</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#ecg" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="ecg"><div class="card card-body">
<ul>
    <li>I worked as the team leader to complete the design and implementation of the portable electrocardiograph.</li>
    <li>We implemented the circuit and PCB design, PCB projection and welding, Matlab simulation of signal processing, FPGA-based signal processing, FPGA and WeChat applet-based Bluetooth communication, applet display, and functional interface development as a group.</li>
    <li>I worked on circuit design, Matlab simulation signal processing, FPGA-based signal processing, and Bluetooth communication.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="" class="img-fluid img-thumbnail" alt="Project image"></div>
                    <div class="col-sm-9">iGEM Project: Light-regulated expression system of multiple pigment proteins (Gold Medal and Best Open Project)<span style="float: right;">Oct. 2017 - Oct. 2018</span>
                    <br><span style="font-style: italic;">Advisor: Prof. Jiangyun Wang and Prof. Chunbo Lou</span>
                    <br><button class="btn btn-link" type="button" data-toggle="collapse" data-target="#igem" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Click to learn more</button>
                        <div class="collapse" id="igem"><div class="card card-body">
<ul>
    <li>I participated in research and program design in the early stage of the project</li>
    <li>I was responsible for the design of modeling experiments and experimental auxiliary hardware, and participated in the compilation of the project webpage.</li>
</ul>
                        </div></div>
                </div> </div> </div>

                
            </div>
        </div>

        <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <h4>Award</h4>
                <ul>
                    <li><b>Bachelor’s Thesis with Honors</b>, <span style="font-style: italic;">University of Chinese Academy of Sciences</span> <span style="float: right;">2021</span></li>
                    <li><b>Academic Excellence Scholarship (second-class)</b>, <span style="font-style: italic;">University of Chinese Academy of Sciences</span> <span style="float: right;">2019</span></li>
                    <li><b>Merit Student</b>, <span style="font-style: italic;">University of Chinese Academy of Sciences</span> <span style="float: right;">2018 - 2019</span></li>
                    <li><b>Gold Medal, Best Open Project</b>, <span style="font-style: italic;">International Genetically Engineered Machine (iGEM) Foundation</span> <span style="float: right;">2017 - 2018</span></li>
                </ul>
            </div>
    
        </div>
        
        <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <h4>Homepage Template</h4>
                <p>
                    Thanks for the website template from <a href="https://m-niemeyer.github.io/" target="_blank">Michael Niemeyer</a>. Last updated on 12/31/2022<br>
                </p>
            </div>
    
        </div>

        
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    